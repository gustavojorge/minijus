# Guia de Execu√ß√£o do Projeto

Este guia explica como executar o projeto completo, desde a infraestrutura at√© o frontend.

## üìã Pr√©-requisitos

- Docker e Docker Compose instalados
- Vari√°veis de ambiente configuradas (crie um arquivo `.env` na raiz se necess√°rio)

## üöÄ Execu√ß√£o R√°pida (Tudo de uma vez)

```bash
make start-full
```

Este comando ir√°:
1. Construir todas as imagens
2. Subir a infraestrutura (Kafka, Postgres, Elasticsearch, MongoDB, Redis)
3. Iniciar os servi√ßos de coleta de dados (data_collection-api, worker)
4. Iniciar o pipeline (parser, classifier, db_sync)
5. Produzir uma mensagem de exemplo
6. Iniciar os servi√ßos backend (indexer, searcher)
7. Iniciar os servi√ßos de aplica√ß√£o (mock-api, backend-graphql, frontend)

## üìù Execu√ß√£o Passo a Passo

### 1. Subir a Infraestrutura

```bash
make run-infra
```

Ou manualmente:
```bash
docker compose up -d zookeeper kafka kafka-web postgres pgadmin elasticsearch kibana mongo data_collection_redis
```

**Aguarde ~15-20 segundos** para todos os servi√ßos ficarem prontos.

### 2. Criar T√≥picos Kafka com 3 Parti√ß√µes

O pipeline est√° configurado para usar 3 parti√ß√µes por t√≥pico, permitindo processamento paralelo:

```bash
make create-kafka-topics
```

Ou manualmente:
```bash
./scripts/create-kafka-topics.sh
```

Este script cria/atualiza os t√≥picos:
- `lawsuit_raw` (3 parti√ß√µes)
- `lawsuit_structured` (3 parti√ß√µes)
- `lawsuit_classified` (3 parti√ß√µes)

### 3. Verificar se o Kafka est√° funcionando

Acesse o Kafka Web UI: http://localhost:8081

Voc√™ deve ver os 3 t√≥picos listados, cada um com 3 parti√ß√µes.

### 4. Iniciar os Servi√ßos de Coleta de Dados

```bash
make run-data-collection-services
```

Ou manualmente:
```bash
docker compose up -d data_collection-api data_collection_worker
```

Isso iniciar√°:
- **data_collection-api**: API para receber requisi√ß√µes de coleta de processos
- **data_collection_worker**: Worker Celery que processa as coletas e publica no Kafka

**Aguarde alguns segundos** para os servi√ßos ficarem prontos.

### 5. Iniciar o Pipeline (com Escalabilidade)

O pipeline est√° configurado para rodar com 3 inst√¢ncias de `parser` e `classifier` para aproveitar o paralelismo das 3 parti√ß√µes:

```bash
make scale-pipeline
```

Ou manualmente:
```bash
docker compose up -d --scale parser=3 --scale classifier=3 parser classifier db_sync
```

**Nota:** Cada inst√¢ncia de `parser` e `classifier` processar√° uma parti√ß√£o diferente, permitindo processamento paralelo de at√© 3 mensagens simultaneamente.

Para iniciar apenas 1 inst√¢ncia de cada:
```bash
make run-pipeline-apps
```

Isso iniciar√°:
- **parser**: Consome `lawsuit_raw` e publica em `lawsuit_structured`
- **classifier**: Consome `lawsuit_structured` e publica em `lawsuit_classified`
- **db_sync**: Consome `lawsuit_classified` e salva no PostgreSQL

### 6. Produzir uma Mensagem de Exemplo

```bash
make produce-example-message
```

Ou manualmente:
```bash
docker compose up initial-payload-producer
```

Isso ir√°:
- Ler o arquivo `initial_payload_producer/lawsuit.json`
- Publicar no t√≥pico `lawsuit_raw`
- O pipeline processar√° automaticamente: `raw ‚Üí structured ‚Üí classified`

### 7. Iniciar os Servi√ßos Backend

```bash
make run-backend-services
```

Ou manualmente:
```bash
docker compose up -d indexer-api searcher-api
```

Isso iniciar√°:
- **indexer-api**: Consome `lawsuit_classified` e indexa no Elasticsearch
- **searcher-api**: API de busca no Elasticsearch

**Aguarde alguns segundos** para o indexer processar a mensagem.

### 8. Iniciar os Servi√ßos de Aplica√ß√£o

```bash
make run-app-services
```

Ou manualmente:
```bash
docker compose up -d mock-api backend-graphql frontend
```

## üß™ Testar o Fluxo Completo

### 1. Verificar se o processo foi indexado

Acesse o Kibana: http://localhost:5601

Ou verifique diretamente no Elasticsearch:
```bash
curl http://localhost:9200/lawsuits/_search?pretty
```

### 2. Buscar no Frontend (Processo j√° indexado)

Acesse: http://localhost:3000

Busque pelo n√∫mero do processo: `1277567-49.2023.8.09.0001`

Este processo deve ser encontrado imediatamente se foi indexado pelo pipeline.

### 3. Testar Coleta Autom√°tica (Processo n√£o indexado)

Para testar o fluxo completo de coleta:

1. **Busque por um CNJ que n√£o existe no Elasticsearch** (ex: `0710802-55.2018.8.02.0001`)

2. **O sistema ir√°:**
   - Verificar no searcher (n√£o encontrar√°)
   - Chamar a API de coleta automaticamente
   - Exibir mensagem de "Processo em coleta" no frontend

3. **Aguarde alguns minutos** enquanto:
   - O worker coleta o processo
   - Publica no Kafka (`lawsuit_raw`)
   - O pipeline processa: `raw ‚Üí structured ‚Üí classified`
   - O indexer indexa no Elasticsearch

4. **Tente buscar novamente** - o processo deve aparecer agora!

### 4. Verificar Logs da Coleta

```bash
# Logs da API de coleta
make logs-data-collection

# Ou individualmente
docker compose logs -f data_collection-api
docker compose logs -f data_collection_worker
```

### 5. Verificar os Logs

```bash
# Logs do indexer (para ver se processou do Kafka)
make logs-indexer

# Logs do pipeline
make logs-pipeline

# Logs da coleta de dados
make logs-data-collection

# Todos os logs
make logs
```

## üîç Verificar o Fluxo no Kafka

1. Acesse http://localhost:8081
2. Verifique os t√≥picos:
   - `lawsuit_raw`: Mensagem inicial
   - `lawsuit_structured`: Mensagem processada pelo parser
   - `lawsuit_classified`: Mensagem classificada

## üõ†Ô∏è Comandos √öteis

```bash
# Parar tudo
make stop-all

# Ver logs de um servi√ßo espec√≠fico
docker compose logs -f indexer-api

# Reconstruir um servi√ßo espec√≠fico
docker compose build indexer-api
docker compose up -d indexer-api

# Ver status de todos os servi√ßos
docker compose ps

# Limpar tudo (volumes inclu√≠dos)
docker compose down -v
```

## üîÑ Fluxo Completo de Dados

### Fluxo 1: Pipeline Inicial (Mensagem de Exemplo)
```
1. initial_payload_producer
   ‚Üì (publica em lawsuit_raw)
2. parser
   ‚Üì (publica em lawsuit_structured)
3. classifier
   ‚Üì (publica em lawsuit_classified)
4. db_sync
   ‚Üì (salva no PostgreSQL)
5. indexer-api (consome lawsuit_classified)
   ‚Üì (indexa no Elasticsearch)
6. searcher-api
   ‚Üì (busca no Elasticsearch)
7. backend-graphql
   ‚Üì (exp√µe GraphQL)
8. frontend
   ‚Üì (consome GraphQL)
```

### Fluxo 2: Coleta Autom√°tica (Processo n√£o encontrado)
```
1. Usu√°rio busca CNJ no frontend
   ‚Üì
2. backend-graphql chama searcher-api
   ‚Üì (n√£o encontra - hits: 0)
3. backend-graphql chama data_collection-api
   ‚Üì
4. data_collection-api verifica cache (MongoDB)
   ‚Üì (n√£o encontra)
5. data_collection-api enfileira tarefa no Redis
   ‚Üì
6. data_collection_worker processa coleta
   ‚Üì (coleta dados do tribunal)
7. data_collection_worker salva no MongoDB
   ‚Üì
8. data_collection_worker publica no Kafka (lawsuit_raw)
   ‚Üì
9. parser processa
   ‚Üì (publica em lawsuit_structured)
10. classifier processa
   ‚Üì (publica em lawsuit_classified)
11. indexer-api indexa no Elasticsearch
   ‚Üì
12. Pr√≥xima busca: processo encontrado! ‚úÖ
```

## üìà Escalabilidade do Pipeline

O pipeline est√° configurado para escalabilidade horizontal usando Kafka com m√∫ltiplas parti√ß√µes:

### Configura√ß√£o Atual

- **3 parti√ß√µes por t√≥pico**: Permite at√© 3 consumidores paralelos por t√≥pico
- **Consumer groups configurados**: Evita processamento duplicado
  - `parser-group`: Parser divide as 3 parti√ß√µes entre inst√¢ncias
  - `classifier-group`: Classifier divide as 3 parti√ß√µes entre inst√¢ncias
  - `db-sync-group`: DB Sync processa todas as mensagens
  - `indexer-group`: Indexer processa todas as mensagens

### Como Funciona

```
lawsuit_raw (3 parti√ß√µes)
  ‚îú‚îÄ Parti√ß√£o 0 ‚Üí parser-1 (parser-group)
  ‚îú‚îÄ Parti√ß√£o 1 ‚Üí parser-2 (parser-group)
  ‚îî‚îÄ Parti√ß√£o 2 ‚Üí parser-3 (parser-group)

lawsuit_structured (3 parti√ß√µes)
  ‚îú‚îÄ Parti√ß√£o 0 ‚Üí classifier-1 (classifier-group)
  ‚îú‚îÄ Parti√ß√£o 1 ‚Üí classifier-2 (classifier-group)
  ‚îî‚îÄ Parti√ß√£o 2 ‚Üí classifier-3 (classifier-group)
```

### Escalar Servi√ßos

Para escalar `parser` e `classifier` para 3 inst√¢ncias:

```bash
make scale-pipeline
```

Ou manualmente:
```bash
docker compose up -d --scale parser=3 --scale classifier=3
```

**Importante:**
- O n√∫mero m√°ximo de consumidores √∫teis = n√∫mero de parti√ß√µes
- Com 3 parti√ß√µes, voc√™ pode ter at√© 3 inst√¢ncias de `parser` e `classifier`
- Mais inst√¢ncias que parti√ß√µes resultar√£o em consumidores ociosos

### Verificar Distribui√ß√£o de Parti√ß√µes

Acesse o Kafka Web UI (http://localhost:8081) e verifique:
- T√≥picos com 3 parti√ß√µes cada
- Consumer groups com m√∫ltiplos consumidores
- Distribui√ß√£o de parti√ß√µes entre consumidores

## ‚ö†Ô∏è Troubleshooting

### Kafka n√£o est√° recebendo mensagens
- Verifique se o zookeeper e kafka est√£o rodando: `docker compose ps`
- Verifique os logs: `docker compose logs kafka`

### Indexer n√£o est√° processando
- Verifique se o Kafka est√° acess√≠vel: `docker compose logs indexer-api`
- Verifique se h√° mensagens no t√≥pico `lawsuit_classified` no Kafka Web UI

### Frontend n√£o encontra processos
- Verifique se o Elasticsearch tem dados: `curl http://localhost:9200/lawsuits/_count`
- Verifique os logs do searcher: `docker compose logs searcher-api`
- Verifique os logs do backend-graphql: `docker compose logs backend-graphql`

### Coleta de dados n√£o est√° funcionando
- Verifique se MongoDB e Redis est√£o rodando: `docker compose ps mongo data_collection_redis`
- Verifique os logs da API: `docker compose logs data_collection-api`
- Verifique os logs do worker: `docker compose logs data_collection_worker`
- Verifique se o Kafka est√° acess√≠vel: `docker compose logs kafka`
- Teste a API diretamente: `curl "http://localhost:8200/lawsuit?lawsuit_number=0710802-55.2018.8.02.0001"`

## üìä Portas dos Servi√ßos

- **Frontend**: http://localhost:3000
- **Backend GraphQL**: http://localhost:4000
- **Data Collection API**: http://localhost:8200
- **Searcher API**: http://localhost:8100
- **Indexer API**: http://localhost:8000
- **Mock API**: http://localhost:9777
- **Kafka Web UI**: http://localhost:8081
- **Kibana**: http://localhost:5601
- **Elasticsearch**: http://localhost:9200
- **PostgreSQL**: localhost:5432
- **PgAdmin**: http://localhost:8080
- **MongoDB**: localhost:27017
- **Redis**: localhost:6379

