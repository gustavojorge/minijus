version: '3.8'

services:
  # Infrastructure services
  elasticsearch:
    image: elasticsearch:8.15.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - 9200:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 20s
    networks:
      - app-network

  kibana:
    image: kibana:8.15.2
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch
    networks:
      - app-network

  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - 5432:5432
    volumes:
      - ./db-init:/docker-entrypoint-initdb.d
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB} -h localhost || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - app-network

  # Data Collection API infrastructure
  mongo:
    image: docker.io/library/mongo:8.0
    container_name: data_collection_mongo
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
      MONGO_INITDB_DATABASE: data_collection
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--username", "root", "--password", "example", "--authenticationDatabase", "admin", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s
    networks:
      - app-network

  data_collection_redis:
    image: redis:7-alpine
    container_name: data_collection_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - app-network

  # Kafka infrastructure
  zookeeper:
    image: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - app-network

  kafka:
    image: wurstmeister/kafka:2.12-2.5.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.17.0.1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: DOCKER_NETWORK:PLAINTEXT,LOCALHOST:PLAINTEXT
      KAFKA_LISTENERS: "DOCKER_NETWORK://:9092,LOCALHOST://:29092"
      KAFKA_ADVERTISED_LISTENERS: "DOCKER_NETWORK://kafka:9092,LOCALHOST://127.0.0.1:29092"
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER_NETWORK
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 60s
    networks:
      - app-network

  kafka-web:
    image: tchiotludo/akhq
    container_name: kafka-web
    ports:
      - "8081:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka:9092"
    depends_on:
      - kafka
    networks:
      - app-network

  # Pipeline services
  initial-payload-producer:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_DIR: initial_payload_producer
    container_name: initial-payload-producer
    command:
      - poetry
      - run
      - python
      - main.py
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - app-network

  parser:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_DIR: parser
    command:
      - poetry
      - run
      - python
      - main.py
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./parser/logs:/parser/logs
    networks:
      - app-network
    restart: unless-stopped

  classifier:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_DIR: classifier
    command:
      - poetry
      - run
      - python
      - main.py
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./classifier/logs:/classifier/logs
    networks:
      - app-network
    restart: unless-stopped

  db_sync:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_DIR: db_sync
    container_name: db_sync
    command:
      - poetry
      - run
      - python
      - main.py
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      CLASSIFIED_TOPIC: lawsuit_classified
      PG_HOST: postgres
      PG_PORT: "5432"
      PG_USER: ${POSTGRES_USER}
      PG_PASSWORD: ${POSTGRES_PASSWORD}
      PG_DATABASE: ${POSTGRES_DB}
      RUN_MIGRATIONS: "true"
    volumes:
      - ./db_sync/logs:/db_sync/logs
    networks:
      - app-network

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_DEFAULT_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - 8080:80
    depends_on:
      - postgres
    networks:
      - app-network

  # Data Collection API services
  data_collection-api:
    build: ./data_collection-api
    container_name: data_collection_api
    ports:
      - "8200:8000"
    volumes:
      - ./data_collection-api:/app
      - ./data_collection-api/logs:/app/logs
    environment:
      - LOG_LEVEL=INFO
      - LOG_FILE=logs/app.log
      - ENVIRONMENT=production
      - MONGODB_URI=mongodb://root:example@mongo:27017/data_collection?authSource=admin
      - MONGODB_DATABASE=data_collection
      - REDIS_URL=redis://data_collection_redis:6379/0
      - CRAWLER_TIMEOUT=30
      - BROWSER_HEADLESS=true
      - BROWSER_SLOW_MO=0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      data_collection_redis:
        condition: service_healthy
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - app-network

  data_collection_worker:
    build: ./data_collection-api
    container_name: data_collection_worker
    command: poetry run celery -A app.workers.celery_app worker --loglevel=info
    volumes:
      - ./data_collection-api:/app
      - ./data_collection-api/logs:/app/logs
    environment:
      - LOG_LEVEL=INFO
      - LOG_FILE=logs/app.log
      - ENVIRONMENT=production
      - MONGODB_URI=mongodb://root:example@mongo:27017/data_collection?authSource=admin
      - MONGODB_DATABASE=data_collection
      - REDIS_URL=redis://data_collection_redis:6379/0
      - CRAWLER_TIMEOUT=30
      - BROWSER_HEADLESS=true
      - BROWSER_SLOW_MO=0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      data_collection_redis:
        condition: service_healthy
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - app-network

  # Backend services (searcher project)
  indexer-api:
    build: ./indexer
    container_name: indexer-api
    environment:
      - ES_HOST=http://elasticsearch:9200
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - CLASSIFIED_TOPIC=lawsuit_classified
      - INITIAL_LOAD_ON_START=false
      - LOG_FILE=logs/app.log
      - LOG_LEVEL=INFO
    ports:
      - 8000:8000
    depends_on:
      elasticsearch:
        condition: service_healthy
      kafka:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./indexer/logs:/app/logs
    networks:
      - app-network

  searcher-api:
    build: ./searcher
    container_name: searcher-api
    environment:
      - ES_HOST=http://elasticsearch:9200
    ports:
      - 8100:8000
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./searcher/logs:/app/logs
    networks:
      - app-network

  # Backend services (vertical-product project)
  mock-api:
    build:
      context: ./mock-api
      dockerfile: Dockerfile
    container_name: mock-api
    ports:
      - "9777:9777"
    volumes:
      - ./mock-api:/usr/src/app
      - /usr/src/app/node_modules
    networks:
      - app-network

  backend-graphql:
    build:
      context: ./backend-graphql
      dockerfile: Dockerfile
    container_name: backend-graphql
    ports:
      - "4000:4000"
    environment:
      - EXTERNAL_API_BASE_URL=http://mock-api:9777
      - SEARCHER_API_BASE_URL=http://searcher-api:8000
      - DATA_COLLECTION_API_BASE_URL=http://data_collection-api:8000
    volumes:
      - ./backend-graphql:/usr/src/app
      - /usr/src/app/node_modules
    depends_on:
      - mock-api
      - searcher-api
      - data_collection-api
    networks:
      - app-network

  frontend:
    build:
      context: ./frontend-boilerplate
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_GRAPHQL_URL=http://localhost:4000/graphql
    volumes:
      - ./frontend-boilerplate:/usr/src/app
      - /usr/src/app/node_modules
      - /usr/src/app/.next
    depends_on:
      - backend-graphql
    networks:
      - app-network

volumes:
  esdata:
  postgres_data:
  mongo_data:
  redis_data:

networks:
  app-network:
    driver: bridge

