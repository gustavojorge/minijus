# ExplicaÃ§Ã£o: Workers e Tarefas no Celery

## 1ï¸âƒ£ Onde o Worker Ã© Definido e Como a Tarefa Ã© AtribuÃ­da?

### O Worker NÃƒO Ã© definido no cÃ³digo Python

O **worker** nÃ£o Ã© uma classe ou funÃ§Ã£o no cÃ³digo. Ele Ã© um **processo Python** que roda o Celery e fica "escutando" o Redis esperando por tarefas.

### Fluxo Completo:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASSO 1: DefiniÃ§Ã£o da Tarefa (CÃ³digo Python)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“ Arquivo: app/tasks/lawsuit_tasks.py
dsdsdsds
@celery_app.task(bind=True, max_retries=3, name="app.tasks.lawsuit_tasks.collect_lawsuit_task")
def collect_lawsuit_task(self, cnj: str, max_cache_age_seconds: int = 3600):
    # Esta funÃ§Ã£o Ã© REGISTRADA como uma tarefa Celery
    # O decorador @celery_app.task faz isso automaticamente
    ...
```

**O que acontece aqui:**
- O decorador `@celery_app.task` **registra** a funÃ§Ã£o como uma tarefa
- O Celery cria um "contrato" dizendo: "existe uma tarefa chamada `app.tasks.lawsuit_tasks.collect_lawsuit_task`"
- Mas a funÃ§Ã£o **ainda nÃ£o foi executada**, apenas registrada

---

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASSO 2: InicializaÃ§Ã£o do Worker (Comando)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“ Comando: celery -A app.workers.celery_app worker --loglevel=info

O que este comando faz:
1. Importa app.workers.celery_app (que contÃ©m celery_app)
2. Importa app.tasks.lawsuit_tasks (por causa do include)
3. Registra todas as tarefas encontradas
4. Conecta ao Redis
5. Fica ESPERANDO por mensagens na fila
```

**O worker Ã© um processo que:**
- Roda continuamente (loop infinito)
- Fica "escutando" o Redis
- Quando vÃª uma mensagem, pega e executa a tarefa correspondente

---

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASSO 3: Enfileiramento da Tarefa (API)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“ Arquivo: app/controllers/lawsuit_controller.py

task = collect_lawsuit_task.delay(normalized_cnj, max_cache_age_seconds)
```

**O que `.delay()` faz:**
1. **NÃƒO executa** a funÃ§Ã£o `collect_lawsuit_task()`
2. Cria uma **mensagem JSON** com:
   - Nome da tarefa: `"app.tasks.lawsuit_tasks.collect_lawsuit_task"`
   - Argumentos: `["0710802-55.2018.8.02.0001", 3600]`
   - ID Ãºnico da tarefa
3. Envia essa mensagem para o **Redis** (fila)
4. Retorna imediatamente (nÃ£o espera execuÃ§Ã£o)

---

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASSO 4: Worker Pega e Executa (AutomÃ¡tico)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

O worker (que estÃ¡ rodando em outro processo/container):
1. VÃª a mensagem no Redis
2. LÃª o nome da tarefa: "app.tasks.lawsuit_tasks.collect_lawsuit_task"
3. Procura a funÃ§Ã£o registrada com esse nome
4. Executa: collect_lawsuit_task("0710802-55.2018.8.02.0001", 3600)
5. Salva o resultado no Redis (opcional)
```

---

## ðŸ“ Resumo: Onde Cada Coisa Acontece

| Componente | Onde estÃ¡ | O que faz |
|------------|-----------|-----------|
| **DefiniÃ§Ã£o da Tarefa** | `app/tasks/lawsuit_tasks.py` | FunÃ§Ã£o com `@celery_app.task` |
| **Registro da Tarefa** | Quando o worker inicia | Celery registra todas as tarefas |
| **Enfileiramento** | `app/controllers/lawsuit_controller.py` | `task.delay()` envia para Redis |
| **Worker (Processo)** | Container separado | Processo que roda `celery worker` |
| **ExecuÃ§Ã£o** | Dentro do worker | Worker pega mensagem e executa |

---

## 2ï¸âƒ£ Por Que um Container Separado para o Worker?

### OpÃ§Ã£o 1: Container Separado (Atual) âœ…

```yaml
services:
  api:
    command: uvicorn app.main:app ...
    
  worker:
    command: celery -A app.workers.celery_app worker ...
```

**Vantagens:**
1. **SeparaÃ§Ã£o de Responsabilidades**
   - API: apenas recebe requisiÃ§Ãµes HTTP
   - Worker: apenas processa tarefas
   - FÃ¡cil de entender e debugar

2. **Escalabilidade Independente**
   ```bash
   # Pode escalar workers sem afetar a API
   docker compose up -d --scale worker=5
   ```
   - Se tiver muitas tarefas, adiciona mais workers
   - API continua respondendo rÃ¡pido

3. **Isolamento de Recursos**
   - Se um worker travar, nÃ£o afeta a API
   - Pode configurar limites de memÃ³ria/CPU separados
   - Reiniciar worker nÃ£o derruba a API

4. **Deploy Independente**
   - Pode atualizar workers sem reiniciar API
   - Ãštil em produÃ§Ã£o

5. **Monitoramento Separado**
   - Logs separados
   - MÃ©tricas separadas
   - FÃ¡cil identificar problemas

---

### OpÃ§Ã£o 2: Mesmo Container (Alternativa)

VocÃª **poderia** rodar tudo no mesmo container:

```yaml
services:
  api:
    command: sh -c "uvicorn app.main:app ... & celery -A app.workers.celery_app worker ... & wait"
```

**Desvantagens:**
- âŒ Se worker travar, pode afetar API
- âŒ NÃ£o pode escalar workers independentemente
- âŒ Logs misturados
- âŒ Mais difÃ­cil de debugar
- âŒ Reiniciar worker derruba API

---

## ðŸŽ¯ Quando Usar Cada Abordagem?

### Container Separado (Recomendado) âœ…
- âœ… ProduÃ§Ã£o
- âœ… Quando precisa escalar workers
- âœ… Quando quer isolamento
- âœ… Quando tem muitos workers

### Mesmo Container
- âš ï¸ Apenas desenvolvimento/testes
- âš ï¸ Quando recursos sÃ£o muito limitados
- âš ï¸ Quando Ã© um projeto pequeno

---

## ðŸ” Exemplo PrÃ¡tico: Como Funciona na PrÃ¡tica

### CenÃ¡rio: 100 requisiÃ§Ãµes simultÃ¢neas

**Com container separado:**
```
API Container: Recebe 100 requisiÃ§Ãµes â†’ Enfileira 100 tarefas â†’ Responde em 200ms
Worker Container 1: Processa tarefa 1
Worker Container 2: Processa tarefa 2
Worker Container 3: Processa tarefa 3
...
Worker Container 10: Processa tarefa 10
```

**Com mesmo container:**
```
Container: Recebe 100 requisiÃ§Ãµes â†’ Enfileira 100 tarefas â†’ Tenta processar tudo â†’ Pode travar
```

---

## ðŸ“ Resumo Final

1. **Worker nÃ£o Ã© cÃ³digo, Ã© um processo** que roda `celery worker`
2. **Tarefa Ã© definida** com `@celery_app.task` no cÃ³digo
3. **Tarefa Ã© enfileirada** com `.delay()` que envia mensagem para Redis
4. **Worker pega automaticamente** a mensagem do Redis e executa
5. **Container separado** permite escalabilidade, isolamento e melhor organizaÃ§Ã£o

---

## ðŸ§ª Teste PrÃ¡tico

Para ver o worker em aÃ§Ã£o:

```bash
# Ver tarefas registradas
docker exec data_collection_worker celery -A app.workers.celery_app inspect registered

# Ver workers ativos
docker exec data_collection_worker celery -A app.workers.celery_app inspect active

# Ver fila no Redis
docker exec data_collection_redis redis-cli
> LLEN celery
> LRANGE celery 0 -1
```

